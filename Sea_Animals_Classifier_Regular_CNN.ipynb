{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2               as cv\n",
    "import numpy             as np\n",
    "import pandas            as pd\n",
    "import seaborn           as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import visualkeras\n",
    "from imutils               import paths\n",
    "from sklearn.utils         import shuffle\n",
    "from urllib.request        import urlopen\n",
    "from sklearn.decomposition import PCA\n",
    "from IPython.display       import Image\n",
    "from tqdm                  import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models              import Sequential, load_model\n",
    "from tensorflow.keras.preprocessing       import image\n",
    "from tensorflow.keras.utils               import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks           import ModelCheckpoint,EarlyStopping\n",
    "from tensorflow.keras.layers              import Conv2D,Flatten,MaxPooling2D,Dense,Dropout,SpatialDropout2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img,array_to_img\n",
    "from keras.layers                         import BatchNormalization, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-) Data Peparation\n",
    "\n",
    "Data Preprocessing + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path        = \"Dataset\"\n",
    "target_size        = (300,225)\n",
    "labels_sea_animals = {\"Clams\"          : 0,\n",
    "                      \"Corals\"         : 1,\n",
    "                      \"Crabs\"          :2,\n",
    "                      \"Dolphin\"        :3,\n",
    "                      \"Eel\"            :4,\n",
    "                      \"Fish\"           :5,\n",
    "                      \"Jelly_Fish\"     :6,\n",
    "                      \"Lobster\"        :7,\n",
    "                      \"Nudibranchs\"    :8,\n",
    "                      \"Octopus\"        :9,\n",
    "                      \"Otter\"          :10,\n",
    "                      \"Penguin\"        :11,\n",
    "                      \"Puffers\"        :12,\n",
    "                      \"Sea_Rays\"       :13,\n",
    "                      \"Sea_Urchins\"    :14,\n",
    "                      \"Seahorse\"       :15,\n",
    "                      \"Seal\"           :16,\n",
    "                      \"Sharks\"         :17,\n",
    "                      \"Shrimp\"         :18,\n",
    "                      \"Squid\"          :19,\n",
    "                      \"Starfish\"       :20,\n",
    "                      \"Turtle_Tortoise\":21,\n",
    "                      \"Whale\"          :22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data Function\n",
    "def load_data_from_directory(directory, target_size, labels_mapping):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            img_path  = os.path.join(class_path, img_name)\n",
    "            img       = load_img(img_path, target_size=target_size)\n",
    "            img_array = img_to_array(img)\n",
    "            images.append(img_array)\n",
    "            labels.append(labels_mapping[class_name])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "x_data, y_data = load_data_from_directory(directory=folder_path,\n",
    "                                          target_size=target_size,\n",
    "                                          labels_mapping=labels_sea_animals)\n",
    "#Train-Validation-Test Split 70%-15%-15%\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(x_data, y_data, test_size=0.3, random_state=42) # 70% train, 30% temp\n",
    "X_val, X_test, y_val, y_test     = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42) # 15% validaton, 15% test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
